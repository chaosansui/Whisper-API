import os
# ä¼˜åŒ–æ˜¾å­˜åˆ†é…ç­–ç•¥ï¼Œé˜²æ­¢ç¢Žç‰‡åŒ–
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"

import torch
import logging
import asyncio
import uvicorn
import time
import setproctitle
from fastapi import FastAPI, UploadFile, File, HTTPException, Query
from contextlib import asynccontextmanager
from pydantic import BaseModel
from typing import Optional
from whisper_asr import WhisperASR
from config import Config

# è®¾ç½®è¿›ç¨‹å
setproctitle.setproctitle("whisper_server")

# é…ç½®æ—¥å¿—
logging.basicConfig(level=Config.LOGGING["level"], format=Config.LOGGING["format"])
logger = logging.getLogger(__name__)

# --- æ•°æ®æ¨¡åž‹ ---
class AudioResponse(BaseModel):
    transcription: str
    language: str = "auto"
    detected_language: str = "unknown"
    processing_time: float

# --- å…¨å±€å®žä¾‹ ---
whisper_asr = WhisperASR()

# --- ç”Ÿå‘½å‘¨æœŸç®¡ç† ---
@asynccontextmanager
async def lifespan(app: FastAPI):
    """æœåŠ¡å¯åŠ¨ä¸Žå…³é—­ç®¡ç†"""
    try:
        logger.info("ðŸš€ å¯åŠ¨æœåŠ¡ï¼Œæ­£åœ¨åŠ è½½æ¨¡åž‹...")
        device_info = Config.get_device_info()
        logger.info(f"ðŸ“Š ç¡¬ä»¶çŽ¯å¢ƒ: {device_info}")
        
        # é¢„åŠ è½½æ¨¡åž‹
        whisper_asr.load_models()
        logger.info("âœ… æœåŠ¡å¯åŠ¨å®Œæˆï¼Œæ¨¡åž‹å·²å°±ç»ª")
        yield
        
    except Exception as e:
        logger.error(f"âŒ æœåŠ¡å¯åŠ¨å¤±è´¥: {e}")
        raise
    finally:
        logger.info("ðŸ›‘ æœåŠ¡å…³é—­ï¼Œæ­£åœ¨æ¸…ç†æ˜¾å­˜...")
        whisper_asr.clear_gpu_memory()

# --- FastAPI åº”ç”¨ ---
app = FastAPI(
    title="Whisper ASR API (LLM Enhanced)",
    description="åŸºäºŽ Whisper Large-v3 + Qwen LLM çš„é«˜ç²¾åº¦è¯­éŸ³è¯†åˆ«æœåŠ¡",
    version="2.0.0",
    lifespan=lifespan
)

# --- æ ¸å¿ƒæŽ¥å£ ---

@app.post("/transcribe", response_model=AudioResponse, summary="è¯­éŸ³è½¬æ–‡å­—(ç»Ÿä¸€æŽ¥å£)")
async def transcribe_audio(
    file: UploadFile = File(..., description="éŸ³é¢‘æ–‡ä»¶ (wav, mp3, m4a, flac, ogg, aac)"),
    forced_language: Optional[str] = Query(None, description="å¼ºåˆ¶æŒ‡å®šè¯­è¨€: zh, en, yue, auto"),
    session_id: Optional[str] = Query(None, description="ä¼šè¯ID (ç”¨äºŽç»´æŒä¸Šä¸‹æ–‡è¿žè´¯æ€§)"),
    use_context: bool = Query(True, description="æ˜¯å¦å¯ç”¨ä¸Šä¸‹æ–‡è®°å¿†")
):
    """
    ç»Ÿä¸€çš„éŸ³é¢‘è½¬å½•æŽ¥å£ã€‚
    - æ”¯æŒ VAD è¯­éŸ³æ´»åŠ¨æ£€æµ‹
    - æ”¯æŒ LLM è¯­ä¹‰æ¶¦è‰²
    - æ”¯æŒ å¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡è®°å¿†
    """
    try:
        if not whisper_asr.model_loaded:
            raise HTTPException(status_code=503, detail="æ¨¡åž‹æ­£åœ¨åŠ è½½ä¸­ï¼Œè¯·ç¨åŽå†è¯•")
        
        start_time = time.time()
        
        # 1. æ ¼å¼éªŒè¯
        allowed_exts = ('.wav', '.mp3', '.m4a', '.flac', '.ogg', '.aac')
        if not file.filename.lower().endswith(allowed_exts):
            raise HTTPException(status_code=400, detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file.filename}")
        
        # 2. è¯»å–æ–‡ä»¶
        audio_bytes = await file.read()
        if not audio_bytes:
            raise HTTPException(status_code=400, detail="æ–‡ä»¶å†…å®¹ä¸ºç©º")
        
        logger.info(f"ðŸ“¥ æŽ¥æ”¶è¯·æ±‚ | æ–‡ä»¶: {file.filename} | å¤§å°: {len(audio_bytes)/1024:.1f}KB | ä¼šè¯: {session_id}")
        
        # 3. å¼‚æ­¥æ‰§è¡Œè½¬å½• (é¿å…é˜»å¡žä¸»çº¿ç¨‹)
        loop = asyncio.get_event_loop()
        transcription, detected_lang = await loop.run_in_executor(
            None, 
            whisper_asr.transcribe_audio, 
            audio_bytes, 
            forced_language,
            session_id,
            use_context
        )
        
        process_time = time.time() - start_time
        logger.info(f"ðŸ“¤ å¤„ç†å®Œæˆ | è€—æ—¶: {process_time:.2f}s | è¯­è¨€: {detected_lang}")
        
        return AudioResponse(
            transcription=transcription, 
            language="auto",
            detected_language=detected_lang,
            processing_time=process_time
        )
        
    except torch.cuda.OutOfMemoryError:
        logger.critical("ðŸš¨ GPU æ˜¾å­˜ä¸è¶³ï¼Œå°è¯•ç´§æ€¥æ¸…ç†")
        whisper_asr.clear_gpu_memory()
        raise HTTPException(status_code=500, detail="æœåŠ¡å™¨æ˜¾å­˜ä¸è¶³ï¼Œè¯·ç¨åŽé‡è¯•")
    except Exception as e:
        logger.error(f"âŒ å¤„ç†å¼‚å¸¸: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# --- ä¸Šä¸‹æ–‡ç®¡ç†æŽ¥å£ ---

@app.delete("/context/{session_id}", summary="æ¸…é™¤æŒ‡å®šä¼šè¯è®°å¿†")
async def clear_session_context(session_id: str):
    whisper_asr.clear_context_cache(session_id)
    return {"status": "success", "message": f"ä¼šè¯ {session_id} ä¸Šä¸‹æ–‡å·²æ¸…é™¤"}

@app.delete("/context", summary="æ¸…é™¤æ‰€æœ‰ä¼šè¯è®°å¿†")
async def clear_all_context():
    whisper_asr.clear_context_cache()
    return {"status": "success", "message": "æ‰€æœ‰ä¸Šä¸‹æ–‡ç¼“å­˜å·²é‡ç½®"}

# --- è¾…åŠ©æŽ¥å£ ---

@app.get("/", summary="æœåŠ¡çŠ¶æ€")
async def root():
    return {
        "service": "Whisper ASR Pro",
        "status": "running" if whisper_asr.model_loaded else "loading",
        "gpu": torch.cuda.get_device_name(0) if torch.cuda.is_available() else "cpu",
        "features": ["VAD", "BeamSearch", "LLM-Correction", "Context-Aware"]
    }

@app.get("/health", summary="å¥åº·æ£€æŸ¥")
async def health_check():
    return {"status": "healthy", "uptime": time.time()}

if __name__ == "__main__":
    logger.info(f"ðŸš€ æœåŠ¡å¯åŠ¨ä¸­ -> http://{Config.API['host']}:{Config.API['port']}")
    uvicorn.run(
        app,
        host=Config.API["host"],
        port=Config.API["port"],
        timeout_keep_alive=Config.API["timeout_keep_alive"],
        log_level=Config.API["log_level"]
    )