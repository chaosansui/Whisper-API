import os
# è®¾ç½® CUDA è®¾å¤‡å’Œå†…å­˜ç®¡ç†ç­–ç•¥
os.environ["CUDA_VISIBLE_DEVICES"] = "2"
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"

import torch
import logging
import asyncio
import uvicorn
from fastapi import FastAPI, UploadFile, File, HTTPException, Query
from contextlib import asynccontextmanager
from pydantic import BaseModel
from typing import Optional
import time
from whisper_asr import WhisperASR
from config import Config

# é…ç½®æ—¥å¿—
logging.basicConfig(level=Config.LOGGING["level"], format=Config.LOGGING["format"])
logger = logging.getLogger(__name__)

# å®šä¹‰å“åº”æ¨¡å‹
class AudioResponse(BaseModel):
    transcription: str
    language: str = "auto"
    detected_language: str = "unknown"

class CorrectionRequest(BaseModel):
    wrong: str
    correct: str

class BatchCorrectionRequest(BaseModel):
    corrections: dict

# åˆ›å»ºå…¨å±€å®ä¾‹
whisper_asr = WhisperASR()

@asynccontextmanager
async def lifespan(app: FastAPI):
    """FastAPI ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    try:
        logger.info("ğŸš€ å¯åŠ¨æœåŠ¡ï¼ŒåŠ è½½æ¨¡å‹ä¸­...")
        device_info = Config.get_device_info()
        logger.info(f"ğŸ“Š è®¾å¤‡ä¿¡æ¯: {device_info}")
        
        whisper_asr.load_models()
        logger.info("âœ… æœåŠ¡å¯åŠ¨å®Œæˆ")
        yield
        
    except Exception as e:
        logger.error(f"âŒ æœåŠ¡å¯åŠ¨å¤±è´¥: {e}")
        raise
    finally:
        logger.info("ğŸ›‘ æœåŠ¡å…³é—­ï¼Œæ¸…ç†èµ„æº...")
        whisper_asr.clear_gpu_memory()

# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(
    title="Whisperè¯­éŸ³è¯†åˆ«API",
    description="åŸºäºWhisperçš„å¤šè¯­è¨€è¯­éŸ³è¯†åˆ«æœåŠ¡",
    version="1.0.0",
    lifespan=lifespan
)

@app.post("/transcribe", response_model=AudioResponse)
async def transcribe_audio(
    file: UploadFile = File(..., description="éŸ³é¢‘æ–‡ä»¶ (æ”¯æŒ wav, mp3, m4a, flac, ogg, aac)"),
    forced_language: Optional[str] = Query(None, description="å¼ºåˆ¶æŒ‡å®šè¯­è¨€: yue(ç²¤è¯­), zh(ä¸­æ–‡), en(è‹±æ–‡), auto(è‡ªåŠ¨æ£€æµ‹)")
):
    """éŸ³é¢‘è½¬å½•æ¥å£"""
    try:
        if not whisper_asr.model_loaded:
            raise HTTPException(status_code=503, detail="æ¨¡å‹æœªåŠ è½½ï¼ŒæœåŠ¡ä¸å¯ç”¨")
        
        start_time = time.time()
        
        # æ–‡ä»¶æ ¼å¼éªŒè¯
        allowed_extensions = ('.wav', '.mp3', '.m4a', '.flac', '.ogg', '.aac')
        if not file.filename.lower().endswith(allowed_extensions):
            raise HTTPException(status_code=400, detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼")
        
        # æ–‡ä»¶å¤§å°éªŒè¯
        audio_bytes = await file.read()
        if len(audio_bytes) == 0:
            raise HTTPException(status_code=400, detail="ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶ä¸ºç©º")
        
        logger.info(f"æ”¶åˆ°éŸ³é¢‘æ–‡ä»¶: {file.filename}, å¤§å°: {len(audio_bytes)} bytes")
        
        # å¼‚æ­¥å¤„ç†è½¬å½•
        loop = asyncio.get_event_loop()
        transcription, detected_language = await loop.run_in_executor(
            None, 
            whisper_asr.transcribe_audio, 
            audio_bytes, 
            forced_language
        )
        
        total_time = time.time() - start_time
        logger.info(f"è¯·æ±‚å¤„ç†å®Œæˆ - è€—æ—¶: {total_time:.2f}ç§’, è¯­è¨€: {detected_language}")
        
        return AudioResponse(
            transcription=transcription, 
            language="auto",
            detected_language=detected_language
        )
        
    except HTTPException:
        raise
    except torch.cuda.OutOfMemoryError:
        logger.error("GPUå†…å­˜ä¸è¶³ï¼Œæ¸…ç†å†…å­˜")
        whisper_asr.clear_gpu_memory()
        raise HTTPException(status_code=500, detail="GPUå†…å­˜ä¸è¶³ï¼Œè¯·é‡è¯•")
    except Exception as e:
        logger.error(f"å¤„ç†å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å¤„ç†å¤±è´¥: {str(e)}")

@app.post("/vocabulary/add", summary="æ·»åŠ è¯æ±‡ä¿®æ­£")
async def add_correction(correction: CorrectionRequest):
    """æ·»åŠ è‡ªå®šä¹‰è¯æ±‡ä¿®æ­£"""
    try:
        whisper_asr.add_custom_correction(correction.wrong, correction.correct)
        
        logger.info(f"æ·»åŠ è¯æ±‡ä¿®æ­£: '{correction.wrong}' -> '{correction.correct}'")
        return {
            "message": "ä¿®æ­£æ·»åŠ æˆåŠŸ",
            "correction": f"'{correction.wrong}' -> '{correction.correct}'"
        }
        
    except Exception as e:
        logger.error(f"æ·»åŠ ä¿®æ­£å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ·»åŠ ä¿®æ­£å¤±è´¥: {str(e)}")

@app.post("/vocabulary/batch_add", summary="æ‰¹é‡æ·»åŠ è¯æ±‡ä¿®æ­£")
async def batch_add_corrections(batch_correction: BatchCorrectionRequest):
    """æ‰¹é‡æ·»åŠ è¯æ±‡ä¿®æ­£"""
    try:
        if not isinstance(batch_correction.corrections, dict):
            raise HTTPException(status_code=400, detail="ä¿®æ­£æ•°æ®æ ¼å¼é”™è¯¯ï¼Œåº”ä¸ºå­—å…¸ç±»å‹")
        
        whisper_asr.batch_add_corrections(batch_correction.corrections)
        
        logger.info(f"æ‰¹é‡æ·»åŠ  {len(batch_correction.corrections)} ä¸ªä¿®æ­£")
        return {
            "message": f"æ‰¹é‡æ·»åŠ  {len(batch_correction.corrections)} ä¸ªä¿®æ­£æˆåŠŸ",
            "count": len(batch_correction.corrections)
        }
        
    except Exception as e:
        logger.error(f"æ‰¹é‡æ·»åŠ ä¿®æ­£å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡æ·»åŠ ä¿®æ­£å¤±è´¥: {str(e)}")

@app.get("/vocabulary/stats", summary="è·å–è¯æ±‡è¡¨ç»Ÿè®¡")
async def get_vocabulary_stats():
    """è·å–è¯æ±‡è¡¨ç»Ÿè®¡ä¿¡æ¯"""
    try:
        stats = whisper_asr.get_vocabulary_stats()
        return {
            "message": "è¯æ±‡è¡¨ç»Ÿè®¡è·å–æˆåŠŸ",
            "statistics": stats
        }
    except Exception as e:
        logger.error(f"è·å–è¯æ±‡è¡¨ç»Ÿè®¡å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–ç»Ÿè®¡å¤±è´¥: {str(e)}")

@app.get("/", summary="æœåŠ¡é¦–é¡µ")
async def root():
    """æ ¹è·¯å¾„ - æœåŠ¡ä¿¡æ¯"""
    device_info = Config.get_device_info()
    
    return {
        "message": "Whisperå¤šè¯­è¨€è¯­éŸ³è¯†åˆ«æœåŠ¡",
        "version": "1.0.0",
        "status": "è¿è¡Œä¸­" if whisper_asr.model_loaded else "å¯åŠ¨ä¸­",
        "device_info": device_info,
        "supported_languages": ["auto", "yue", "zh", "en"],
        "features": [
            "å¤šè¯­è¨€è¯­éŸ³è¯†åˆ«",
            "è‡ªåŠ¨è¯­è¨€æ£€æµ‹", 
            "é•¿éŸ³é¢‘åˆ†å—å¤„ç†",
            "ç»Ÿä¸€è¯æ±‡çŸ«æ­£",
            "å†…å­˜ä½¿ç”¨ä¼˜åŒ–"
        ]
    }

@app.get("/health", summary="å¥åº·æ£€æŸ¥")
async def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return {
        "status": "healthy" if whisper_asr.model_loaded else "unhealthy",
        "timestamp": time.time(),
        "model_loaded": whisper_asr.model_loaded
    }

@app.get("/info", summary="æ¨¡å‹ä¿¡æ¯")
async def model_info():
    """æ¨¡å‹ä¿¡æ¯æ¥å£"""
    if not whisper_asr.model_loaded:
        raise HTTPException(status_code=503, detail="æ¨¡å‹æœªåŠ è½½")
    
    return whisper_asr.get_model_info()
# åœ¨ç°æœ‰çš„è·¯ç”±åé¢æ·»åŠ ä»¥ä¸‹æ–°è·¯ç”±

@app.post("/transcribe_with_context", response_model=AudioResponse)
async def transcribe_audio_with_context(
    file: UploadFile = File(..., description="éŸ³é¢‘æ–‡ä»¶"),
    forced_language: Optional[str] = Query(None, description="å¼ºåˆ¶æŒ‡å®šè¯­è¨€"),
    session_id: Optional[str] = Query(None, description="ä¼šè¯IDï¼Œç”¨äºç»´æŒä¸Šä¸‹æ–‡"),
    use_context: bool = Query(True, description="æ˜¯å¦ä½¿ç”¨ä¸Šä¸‹æ–‡æç¤ºè¯")
):
    """æ”¯æŒä¸Šä¸‹æ–‡è¿è´¯æ€§çš„éŸ³é¢‘è½¬å½•æ¥å£"""
    try:
        if not whisper_asr.model_loaded:
            raise HTTPException(status_code=503, detail="æ¨¡å‹æœªåŠ è½½ï¼ŒæœåŠ¡ä¸å¯ç”¨")
        
        start_time = time.time()
        
        # æ–‡ä»¶æ ¼å¼éªŒè¯
        allowed_extensions = ('.wav', '.mp3', '.m4a', '.flac', '.ogg', '.aac')
        if not file.filename.lower().endswith(allowed_extensions):
            raise HTTPException(status_code=400, detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼")
        
        # æ–‡ä»¶å¤§å°éªŒè¯
        audio_bytes = await file.read()
        if len(audio_bytes) == 0:
            raise HTTPException(status_code=400, detail="ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶ä¸ºç©º")
        
        logger.info(f"æ”¶åˆ°éŸ³é¢‘æ–‡ä»¶: {file.filename}, å¤§å°: {len(audio_bytes)} bytes, ä¼šè¯ID: {session_id}")
        
        # å¼‚æ­¥å¤„ç†è½¬å½•
        loop = asyncio.get_event_loop()
        transcription, detected_language = await loop.run_in_executor(
            None, 
            whisper_asr.transcribe_audio, 
            audio_bytes, 
            forced_language,
            session_id,
            use_context
        )
        
        total_time = time.time() - start_time
        logger.info(f"ä¸Šä¸‹æ–‡è½¬å½•å®Œæˆ - è€—æ—¶: {total_time:.2f}ç§’, è¯­è¨€: {detected_language}")
        
        return AudioResponse(
            transcription=transcription, 
            language="auto",
            detected_language=detected_language
        )
        
    except HTTPException:
        raise
    except torch.cuda.OutOfMemoryError:
        logger.error("GPUå†…å­˜ä¸è¶³ï¼Œæ¸…ç†å†…å­˜")
        whisper_asr.clear_gpu_memory()
        raise HTTPException(status_code=500, detail="GPUå†…å­˜ä¸è¶³ï¼Œè¯·é‡è¯•")
    except Exception as e:
        logger.error(f"å¤„ç†å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å¤„ç†å¤±è´¥: {str(e)}")

@app.delete("/context/{session_id}", summary="æ¸…ç†æŒ‡å®šä¼šè¯çš„ä¸Šä¸‹æ–‡")
async def clear_session_context(session_id: str):
    """æ¸…ç†æŒ‡å®šä¼šè¯çš„ä¸Šä¸‹æ–‡ç¼“å­˜"""
    try:
        whisper_asr.clear_context_cache(session_id)
        return {"message": f"å·²æ¸…ç†ä¼šè¯ {session_id} çš„ä¸Šä¸‹æ–‡ç¼“å­˜"}
    except Exception as e:
        logger.error(f"æ¸…ç†ä¸Šä¸‹æ–‡ç¼“å­˜å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ¸…ç†å¤±è´¥: {str(e)}")

@app.delete("/context", summary="æ¸…ç†æ‰€æœ‰ä¸Šä¸‹æ–‡ç¼“å­˜")
async def clear_all_context():
    """æ¸…ç†æ‰€æœ‰ä¸Šä¸‹æ–‡ç¼“å­˜"""
    try:
        whisper_asr.clear_context_cache()
        return {"message": "å·²æ¸…ç†æ‰€æœ‰ä¸Šä¸‹æ–‡ç¼“å­˜"}
    except Exception as e:
        logger.error(f"æ¸…ç†ä¸Šä¸‹æ–‡ç¼“å­˜å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ¸…ç†å¤±è´¥: {str(e)}")

@app.get("/context/stats", summary="è·å–ä¸Šä¸‹æ–‡ç¼“å­˜ç»Ÿè®¡")
async def get_context_stats():
    """è·å–ä¸Šä¸‹æ–‡ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
    try:
        model_info = whisper_asr.get_model_info()
        return {
            "context_cache_size": model_info.get("context_cache_size", 0),
            "active_sessions": list(whisper_asr.context_cache.keys()) if hasattr(whisper_asr, 'context_cache') else []
        }
    except Exception as e:
        logger.error(f"è·å–ä¸Šä¸‹æ–‡ç»Ÿè®¡å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–ç»Ÿè®¡å¤±è´¥: {str(e)}")

if __name__ == "__main__":
    logger.info("ğŸš€ Starting Whisper ASR Server...")
    
    uvicorn.run(
        app,
        host=Config.API["host"],
        port=Config.API["port"],
        timeout_keep_alive=Config.API["timeout_keep_alive"],
        log_level=Config.API["log_level"]
    )